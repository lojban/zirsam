Or, in other words, "TODO"
Items marked "-" aren't as important as items marked "+"

###### Release Checklist
 - bnf/convert_bnf.py: DISABLE_HASH = False
 - clean

###### Soon
 + Oh my god, zirsam has HORRIBLE MEMORY ISSUES
    - improved by running gc.collect()
    - But where to run it?
    - Actually, it's "vocab.py" that has horrible memory issues; what happens if you parse a long document?
 - More error checking
    - lai & friends in cmene (depends on dot-side)
    - invalid consonant clusters in words
    - bad fu'ivla (cidrsadifluffle)
 - What about that old '*' on TrackerMatch? Uhm.
    - related to funny bridi_tail that keeps following me around
 - make word_end in morphology.py indexed from 0 instead of 1?
 + Test IPA and other alphabets
 - Don't use "config" for the config.Configuration() object, use "conf"? Or rename config.py to conf.py
 - Add option for progress bar, and maybe auto-detect if you might want progress info. Say... 3 seconds or so
 - Put in GPL licensing or something and other legalese stuff in files that need it
    - what is the legal status of lojban.bnf?
       - Public domain
 - Test: Should be able to run dendrography off of a raw valsi stream (without thaumatology). Write an example!
 - Move HTML-ify to a separate module
 - Move unnecessary files out of zirsam/data/
 - Put parser into quiet mode inside ZOI
 - Also, perhaps an option to *not* be quiet inside ZOI; preventing embedded non-Lojban text
 - Make zirsam runnable from the package again, so that continously building and installing isn't needed

###### Later
 - $ grep -C 2 "XXX\|TODO" */*.bnf *.py */*.py
 - Check for weird/odd/wrong comments. There are probably many...
 - (seperate out the configuration options for each section?)
 - It would be interesting to have an option to disable line-buffering; the user could see the immediate tokenization. (Bleh, meh)
 - How do I like Position? Does it match up with vi, kate, and other editors?
 - Do I like how the Configuration object is propagated? Is there a way to make it more... uhmm
   - Don't use self.config, use self.buffer.config? (the way it is now is more flexible)
 + Make GlyphTable handle multi-length input characters (sampa: {l=?dZEim=s} should be {la.djeims})
 - CLI argument to read stdin from a file
 - Print out tokenization immediatly on input (import tty)
 - Another way to make it faster would be to merge Concat(A, Concat(B, C)) into Concat(A, B, C), at the cost of increased code complexity. (Or, perhaps Concat(A, Concat(B, Concat(C, D))) into Concat(Concat(A, B), Concat(C, D)), without adding more code?)
 + Move/Do lujvo/fuhivla sorting crap in morphology.py instead of token.py
 - Have a config option for zoi to be filtered by the alphabet, or just from what we get
 + could optimize by first parsing sentences and ignoring content? (Well, not reaaaaly an optimization. But better for streaming.) "--flat-parse". Parse in units of the selma'o I. x-sentence-parse-root might be, "NIhO | I | sentence"
    - For parsing long documents, it would probably be best to do parsing at the sentence-level.
    - Unless it isn't actually any faster?
    - In some situations, you might actually want sentence-at-a-time.
 - have switches that enable or disable certain parts of the BNF to allow for grammars designed for other situations
    - Such as...?
 - Investigate cython! (Used to be called pyrex?)
    - Currently (cython 0.12.1; April 2010) doesn't support "yield". Absolutely unusable until it is.
       - It *would* be possible to rewrite it such that each step built up and returned a list

###### Much Later
 - (Have error messages in lojban?)
 - Semantics engine and supporting stuff (Nope. Seperate project.) (Well, maybe not all of it) (bah. Whatever.)
 - Jbovlaste integration
 + learn how to speak lojban
 - Tool to convert words to be spaceless
 - Tool to fix lack of pauses
 - Optimize the parser by not checking optionals until after we know the item following doesn't match?
    - Is this valid?
      - If what follows doesn't match, then it could never match!?
        - unless the following is optional.
        - It would match if you had matched the optional.
          - If it doesn't match, then check the optional.
          - If it matches the following, than it can't match the optional (*UNLESS* the optional is the same thing):
              rule = [FOO] FOO BAR
            match: FOO FOO BAR:
              tries:
                FOO(FOO) BAR(FOO), but fails.
              so, if it matches, but stuff before it fails, then check the optional?
            It is quite likely that the BNF doesn't have stuff in the form [FOO] FOO.
    Conclusion:
      We can put off checking optionals so long as the optional isn't the same as the next part, and I doubt the BNF has anything like that. But this will prolly need more investigation.
 - Only allow real gismu?

###### I don't know what I was writing
 - Test more aspects of morphology, and also for the other modules
 - Make the helper code nicer

###### (probably) NEVER
 - Have an option for inputting by letter type (like CVCCV), which would have been good for debugging morphology but might not be so useful now
 - Make a funny/bad// joke about {tosmabru}
 - If there is demand: xml output
 - Emulate output of jbofihe and camxes and parser3?
 - Add an "--abusive" option zo'o

##### Morphology: I don't care about it anymore
 - Check that each marker in brkwords is properly implemented and documented (Turns out I don't really care)
 - Make sure I didn't accidentally change/deleting anything in BRKWORDS.txt
 - Go through everything I checked off, make sure it really is.



###### Some things I've completed, to make me feel special
 + Use GNU readline! Not being able to edit lines in jbofihe is /so/ annoying
 + Go through morph_test_sentences.txt (And also, get a URL and an original copy)
    (Okay, only half-heartedly. It wasn't so useful.)
 - Make stream(config, stdin) more like stream(stdin, config=None) and make config take care of itself
 - Make thaumatology.py not print valsi type
Ortohgraphy - what happens to capitalized letters with strict ortho?
    * they are garbage
  Resolve recursive import failures
 + Put stdin into Configuration. Probably the best way to deal with quotes
 + lerfu!  (It is done, right?)
 + EncodingTable vs. GlyphTable! !??!
 - Handle whitespace so that the fact that there is a word seperation is returned immediatly, instead of reading 'til the first non-whitespace. Possibilities include returning a Bit for each whitespace, returning a Bit for the first whitespace and merging the rest, or returning a bit that has no value, but is treated as a whitespace, and having the actual whitespace slurped up later.  (I\'m having it just return each whitespace individualy)
 + sumti-6 in the BNF isn't being loaded correctly
 - Check that I am parsing the BNF correctly. For example, the &s in "simple-tense-modal" (I don't know for certain that the way it parses is correct)
 - I think that morphology hack in orthography isn't needed anymore
 + Ah HA! I've figured out how to handle ZOI: Keep a copy of the old crap. Well, ah, we only need to start when we hit a ZOI, but ohh.. Okay, so EVERYTHING must be copied. AH HA! Okay, that is beautiful love. Hit ZOI. Get delim. Get delim offset. Read shit from morphology, until we hit next delim. Get offset. Suck out stuff between the delim's in the old buffer! :D
 - Fold whitespace/boring into the following token!
 + Debug mode for dendrography (Sorta. I have debugging output for it now.)
 X Re-do the magic_bnf objects, carefully defining what each one should return in each case. -- I decided it'd be better to just make what already almost works instead of starting from scratch
 - examine {miklAmalozdAnibelomAmtabelatimos} (Was a morphology issue, Tokens needed another anti-morphology-tokenization variable)
 - Make --token-error print a backtrace on each token instead of dieing? (traceback.print_stack())
 - Check the bottom of the BNF. Are there unimplemented non-formal rules?
 - Study and meditate upon lojban grammar, make grammar parser
 + Check that the BNF is being intepreted properly (The BNF being parsed wrong hasn't been an issue in forever)
 + Make ZOI period-delims behave properly.
 - slinku'i test
 - Do more garbage checking (For example, try {klÃ¡ma} with default settings) (Those are now a sub-selma'o of SELBRI, called CIZYSELBRI)
 - what happened with ZOI? (oops, forgot to put the zoi.content...)
 + Store results of grammar expressions. I should be able to do Tracker.FA ...
 - SELBRI vs. BRIVLA. I think I'm using SELBRI when I should be using BRIVLA.
 - Minimal parse tree printout (check-ish. It's shitty. It's fugly. It could look much nicer.)
 - Implement everything according to http://www.lojban.org/tiki/Magic+Words
    * Make sure that everything interacts properly (More tests could be done, a testsuite could be made...)
 - Check your dotside!
    (Not just dotside. Pauses in general. "ui" vs. ".ui", "alis" vs ".alis". IOW, require all words begining with a vowel to start with a pause instead.) (Shows a message if it isn't dotted.)
 - Make error messages consistant (run "a b")
 - Link to python3, not python3.0. (You actually have 3.1 installed...)
    But other installations might not have a python3! So no. >_>
    Bah, did it anyways.
 - look into proper distribution methods, see the distutils module http://docs.python.org/distutils/
     "package_data" for setup.py
 - Oh god. What did I do. {mi pu viska}
    AGH! That stupid & thing again!
      OKAY. SO. CLEARLY, CONCATENATION HAS GREATER PRECEDENCE THAN &. I"M GLAD THAT WE HAVE DETERMINED THIS TO BE TRUE.
    I LOOK FORWARD TO CONTINUED MUTUAL COOPERATION AND RESPECT.
 - What is up with {do cu puki broda}
    - BNF isn't being parsed right; agh!
    - Check all of those &'s
 - It could be faster! Instead of Xor(Xor(...), A) do Xor(A, Xor(...)). Because that would make it faster? Only if the most common forms are listed first in the BNF. Well, at least the old method might not be faster, but the current one would be faster because it has to run more XOr tests.
 - Have cmalu use bitbuffer.py
